{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GraphSAINT_with_PytorchGeometric",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klL2ZtmK3mgG"
      },
      "source": [
        "References: \n",
        "\n",
        "Fast Graph Representation Learning with PyTorch Geometric\n",
        "https://arxiv.org/abs/1903.02428\n",
        "\n",
        "\n",
        "PyTorch Geometric Github https://github.com/rusty1s/pytorch_geometric/blob/master/examples/graph_saint.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqbdjYYGNTTP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3d5ce39-b86b-4d8a-d5c6-d09bdf0c7b29"
      },
      "source": [
        "# Install required packages of PyTorch Geometric\n",
        "!pip install -q torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "!pip install -q torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 11.9MB 255kB/s \n",
            "\u001b[K     |████████████████████████████████| 24.3MB 137kB/s \n",
            "\u001b[K     |████████████████████████████████| 235kB 11.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.2MB 31.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.4MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imGrKO5YH11-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70510afb-468b-4b54-d56d-bdc827bd735a"
      },
      "source": [
        "# import datasets from pytorch geometric\n",
        "\n",
        "from torch_geometric.datasets import Yelp, Flickr, Amazon\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "\n",
        "dataset = Yelp(root='data/Yelp', transform=NormalizeFeatures())\n",
        "#dataset_amazon = Amazon(root='data/Amazon', name='computers')\n",
        "#dataset_flickr = Flickr(root='data/Flickr', transform=NormalizeFeatures()) # this is an image dataset, so only for demo\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1Juwx8HtDwSzmVIJ31ooVa1WljI4U5JnA into data/Yelp/raw/adj_full.npz... Done.\n",
            "Downloading 1Zy6BZH_zLEjKlEFSduKE5tV9qqA_8VtM into data/Yelp/raw/feats.npy... Done.\n",
            "Downloading 1VUcBGr0T0-klqerjAjxRmAqFuld_SMWU into data/Yelp/raw/class_map.json... Done.\n",
            "Downloading 1NI5pa5Chpd-52eSmLW60OnB3WS5ikxq_ into data/Yelp/raw/role.json... Done.\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It-8StB97H10"
      },
      "source": [
        "# print basic information about the dataset\n",
        "\n",
        "def print_data(input_data):\n",
        "  ''' input_data: pytorch geometric dataset format\n",
        "      prints basic information about the dataset\n",
        "  '''\n",
        "\n",
        "  print()\n",
        "  print(f'Dataset: {input_data}:')\n",
        "  print('======================')\n",
        "  print(f'Number of graphs: {len(input_data)}')\n",
        "  print(f'Number of features: {input_data.num_features}')\n",
        "  print(f'Number of classes: {input_data.num_classes}')\n",
        "\n",
        "  data = input_data[0]  # Get the first graph object.\n",
        "\n",
        "  print()\n",
        "  print(data)\n",
        "  print('===========================================================================================================')\n",
        "\n",
        "  # Gather some statistics about the graph.\n",
        "  print(f'Number of nodes: {data.num_nodes}')\n",
        "  print(f'Number of edges: {data.num_edges}')\n",
        "  print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
        "  #if data.train_mask: # to check if the data is masked with train/val/test mask\n",
        "  #  print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "  #  print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
        "  print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
        "  print(f'Contains self-loops: {data.contains_self_loops()}')\n",
        "  print(f'Is undirected: {data.is_undirected()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1MJ7Br27_6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14aefc6-6640-4f54-f1dc-8cf8895ed667"
      },
      "source": [
        "print_data(dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset: Yelp():\n",
            "======================\n",
            "Number of graphs: 1\n",
            "Number of features: 300\n",
            "Number of classes: 100\n",
            "\n",
            "Data(edge_index=[2, 13954819], test_mask=[716847], train_mask=[716847], val_mask=[716847], x=[716847, 300], y=[716847, 100])\n",
            "===========================================================================================================\n",
            "Number of nodes: 716847\n",
            "Number of edges: 13954819\n",
            "Average node degree: 19.47\n",
            "Contains isolated nodes: False\n",
            "Contains self-loops: True\n",
            "Is undirected: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS54IJNQ9EV1"
      },
      "source": [
        "# define data\n",
        "data = dataset[0] # the first graph object of the dataset (which has just 1 grph anyways)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8RgrdMk57wS"
      },
      "source": [
        "# import graphsaint sampler (explain what this does)\n",
        "from torch_geometric.data import GraphSAINTRandomWalkSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6FJCpbI54dS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92800d76-93ca-4a80-880b-54f6544b1a86"
      },
      "source": [
        "loader = GraphSAINTRandomWalkSampler(data, batch_size=6000, walk_length=2,\n",
        "                                     num_steps=5, sample_coverage=100,\n",
        "                                     save_dir=dataset.processed_dir,\n",
        "                                     num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compute GraphSAINT normalization: : 71705856it [10:35, 112750.99it/s]                            \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygn8F40KNUO2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72df18fc-5b6d-4552-adc6-5d4d29187f65"
      },
      "source": [
        "# just to check how Amazon data looks like \n",
        "for data in loader:\n",
        "  print(data)\n",
        "  #print(data.y)\n",
        "  #print(data.train_mask)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data(edge_index=[2, 316298], edge_norm=[316298], node_norm=[8993], x=[8993, 767], y=[8993])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5C2SFliwJJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b331c29-bedc-4fbc-ecd8-6b57391c0833"
      },
      "source": [
        "# just to check how Yelp data looks like \n",
        "for data in loader:\n",
        "  #print(data)\n",
        "  print(data.y) # one-hot-encoded label\n",
        "  #print(data.train_mask)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 1.,  ..., 0., 0., 1.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WJsV_aKEyMn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b014a9-3090-4abf-8790-60c96b6cabbf"
      },
      "source": [
        "# just to check how Flickr data looks like \n",
        "for data in loader:\n",
        "  #print(data)\n",
        "  print(data.y)\n",
        "  #print(data.train_mask)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([4, 4, 6,  ..., 3, 0, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuQoMNW-AeLA"
      },
      "source": [
        "# import necessary libraries for model building\n",
        "import torch\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsxLwlb3-aPN"
      },
      "source": [
        "# model structure\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(Net, self).__init__()\n",
        "        in_channels = dataset.num_node_features\n",
        "        out_channels = dataset.num_classes\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = torch.nn.Linear(3 * hidden_channels, out_channels)\n",
        "\n",
        "    def set_aggr(self, aggr):\n",
        "        self.conv1.aggr = aggr\n",
        "        self.conv2.aggr = aggr\n",
        "        self.conv3.aggr = aggr\n",
        "\n",
        "    def forward(self, x0, edge_index, edge_weight=None):\n",
        "        x1 = F.relu(self.conv1(x0, edge_index, edge_weight))\n",
        "        x1 = F.dropout(x1, p=0.2, training=self.training)\n",
        "        x2 = F.relu(self.conv2(x1, edge_index, edge_weight))\n",
        "        x2 = F.dropout(x2, p=0.2, training=self.training)\n",
        "        x3 = F.relu(self.conv3(x2, edge_index, edge_weight))\n",
        "        x3 = F.dropout(x3, p=0.2, training=self.training)\n",
        "        x = torch.cat([x1, x2, x3], dim=-1)\n",
        "        x = self.lin(x)\n",
        "        \n",
        "        return x.log_softmax(dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smyEfVmH-PO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a8146cd-e7bb-44e0-e65c-82ddb1ea0715"
      },
      "source": [
        "# define model \n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Net(hidden_channels=256).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): GCNConv(300, 256)\n",
            "  (conv2): GCNConv(256, 256)\n",
            "  (conv3): GCNConv(256, 256)\n",
            "  (lin): Linear(in_features=768, out_features=100, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtwmlyZm-ccI"
      },
      "source": [
        "# train function\n",
        "def train():\n",
        "    model.train()\n",
        "    #model.set_aggr('add' if args.use_normalization else 'mean')\n",
        "\n",
        "    total_loss = total_examples = 0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #if args.use_normalization:\n",
        "        #    edge_weight = data.edge_norm * data.edge_weight\n",
        "        #    out = model(data.x, data.edge_index, edge_weight)\n",
        "        #    loss = F.nll_loss(out, data.y, reduction='none')\n",
        "        #    loss = (loss * data.node_norm)[data.train_mask].sum()\n",
        "        #else:\n",
        "        #    out = model(data.x, data.edge_index)\n",
        "        #    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "        out = model(data.x, data.edge_index)\n",
        "        #loss = F.nll_loss(out, data.y) # for Amazon\n",
        "        loss = F.nll_loss(out[data.train_mask], torch.argmax(data.y[data.train_mask], dim=-1)) # for Yelp\n",
        "        #loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * data.num_nodes\n",
        "        total_examples += data.num_nodes\n",
        "    return total_loss / total_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqWqAXi5-gM6"
      },
      "source": [
        "# test function\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    model.eval()\n",
        "    model.set_aggr('mean')\n",
        "\n",
        "    out = model(data.x.to(device), data.edge_index.to(device))\n",
        "    pred = out.argmax(dim=-1)\n",
        "    #correct = pred.eq(data.y.to(device)) # for Amazon\n",
        "    correct = pred.eq(torch.argmax(data.y, dim=-1).to(device)) # for Yelp\n",
        "\n",
        "    accs = []\n",
        "    for _, mask in data('train_mask', 'val_mask', 'test_mask'):\n",
        "        accs.append(correct[mask].sum().item() / mask.sum().item())\n",
        "    return accs # for Yelp\n",
        "\n",
        "    #accs.append(correct.sum().item()) # for Amazon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OCgKvij51na",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "713ca958-b425-4152-999d-641244336f2d"
      },
      "source": [
        "# print results\n",
        "\n",
        "for epoch in range(1, 51):\n",
        "    loss = train()\n",
        "    accs = test()\n",
        "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {accs[0]:.4f}, '\n",
        "          f'Val: {accs[1]:.4f}, Test: {accs[2]:.4f}') # for Yelp\n",
        "    #print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {accs[0]:.4f}, Test: {accs[1]:.4f}') # for Amazon\n",
        "    #print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}') for Amazon"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01, Loss: 2.9649, Train: 0.5415, Val: 0.5513, Test: 0.5458\n",
            "Epoch: 02, Loss: 3.2837, Train: 0.5404, Val: 0.5495, Test: 0.5464\n",
            "Epoch: 03, Loss: 2.6773, Train: 0.5421, Val: 0.5508, Test: 0.5451\n",
            "Epoch: 04, Loss: 2.4568, Train: 0.5390, Val: 0.5482, Test: 0.5431\n",
            "Epoch: 05, Loss: 2.3303, Train: 0.5421, Val: 0.5508, Test: 0.5451\n",
            "Epoch: 06, Loss: 2.2290, Train: 0.5390, Val: 0.5482, Test: 0.5444\n",
            "Epoch: 07, Loss: 2.1174, Train: 0.5422, Val: 0.5508, Test: 0.5451\n",
            "Epoch: 08, Loss: 2.0672, Train: 0.5422, Val: 0.5513, Test: 0.5451\n",
            "Epoch: 09, Loss: 2.0120, Train: 0.5429, Val: 0.5513, Test: 0.5471\n",
            "Epoch: 10, Loss: 1.9539, Train: 0.5414, Val: 0.5491, Test: 0.5451\n",
            "Epoch: 11, Loss: 1.9080, Train: 0.5404, Val: 0.5477, Test: 0.5444\n",
            "Epoch: 12, Loss: 1.8662, Train: 0.5405, Val: 0.5482, Test: 0.5451\n",
            "Epoch: 13, Loss: 1.8110, Train: 0.5407, Val: 0.5473, Test: 0.5458\n",
            "Epoch: 14, Loss: 1.7682, Train: 0.5428, Val: 0.5500, Test: 0.5464\n",
            "Epoch: 15, Loss: 1.7396, Train: 0.5432, Val: 0.5508, Test: 0.5471\n",
            "Epoch: 16, Loss: 1.6973, Train: 0.5439, Val: 0.5513, Test: 0.5464\n",
            "Epoch: 17, Loss: 1.6573, Train: 0.5440, Val: 0.5513, Test: 0.5464\n",
            "Epoch: 18, Loss: 1.6295, Train: 0.5441, Val: 0.5517, Test: 0.5464\n",
            "Epoch: 19, Loss: 1.5958, Train: 0.5446, Val: 0.5540, Test: 0.5464\n",
            "Epoch: 20, Loss: 1.5611, Train: 0.5442, Val: 0.5526, Test: 0.5464\n",
            "Epoch: 21, Loss: 1.5445, Train: 0.5454, Val: 0.5526, Test: 0.5477\n",
            "Epoch: 22, Loss: 1.5214, Train: 0.5454, Val: 0.5540, Test: 0.5471\n",
            "Epoch: 23, Loss: 1.5027, Train: 0.5464, Val: 0.5535, Test: 0.5484\n",
            "Epoch: 24, Loss: 1.4831, Train: 0.5471, Val: 0.5544, Test: 0.5477\n",
            "Epoch: 25, Loss: 1.4776, Train: 0.5474, Val: 0.5544, Test: 0.5491\n",
            "Epoch: 26, Loss: 1.4701, Train: 0.5469, Val: 0.5553, Test: 0.5504\n",
            "Epoch: 27, Loss: 1.4536, Train: 0.5480, Val: 0.5553, Test: 0.5511\n",
            "Epoch: 28, Loss: 1.4460, Train: 0.5480, Val: 0.5575, Test: 0.5544\n",
            "Epoch: 29, Loss: 1.4353, Train: 0.5488, Val: 0.5566, Test: 0.5531\n",
            "Epoch: 30, Loss: 1.4256, Train: 0.5494, Val: 0.5598, Test: 0.5531\n",
            "Epoch: 31, Loss: 1.4266, Train: 0.5500, Val: 0.5598, Test: 0.5517\n",
            "Epoch: 32, Loss: 1.4208, Train: 0.5507, Val: 0.5607, Test: 0.5537\n",
            "Epoch: 33, Loss: 1.4092, Train: 0.5516, Val: 0.5611, Test: 0.5557\n",
            "Epoch: 34, Loss: 1.4111, Train: 0.5519, Val: 0.5616, Test: 0.5544\n",
            "Epoch: 35, Loss: 1.3993, Train: 0.5516, Val: 0.5598, Test: 0.5544\n",
            "Epoch: 36, Loss: 1.3970, Train: 0.5530, Val: 0.5616, Test: 0.5570\n",
            "Epoch: 37, Loss: 1.4053, Train: 0.5521, Val: 0.5602, Test: 0.5557\n",
            "Epoch: 38, Loss: 1.3924, Train: 0.5537, Val: 0.5611, Test: 0.5570\n",
            "Epoch: 39, Loss: 1.3859, Train: 0.5539, Val: 0.5611, Test: 0.5564\n",
            "Epoch: 40, Loss: 1.3830, Train: 0.5539, Val: 0.5616, Test: 0.5557\n",
            "Epoch: 41, Loss: 1.3763, Train: 0.5537, Val: 0.5638, Test: 0.5550\n",
            "Epoch: 42, Loss: 1.3723, Train: 0.5529, Val: 0.5629, Test: 0.5564\n",
            "Epoch: 43, Loss: 1.3673, Train: 0.5545, Val: 0.5593, Test: 0.5564\n",
            "Epoch: 44, Loss: 1.3748, Train: 0.5542, Val: 0.5611, Test: 0.5577\n",
            "Epoch: 45, Loss: 1.3631, Train: 0.5538, Val: 0.5620, Test: 0.5570\n",
            "Epoch: 46, Loss: 1.3591, Train: 0.5546, Val: 0.5629, Test: 0.5570\n",
            "Epoch: 47, Loss: 1.3557, Train: 0.5551, Val: 0.5624, Test: 0.5584\n",
            "Epoch: 48, Loss: 1.3558, Train: 0.5553, Val: 0.5633, Test: 0.5577\n",
            "Epoch: 49, Loss: 1.3477, Train: 0.5552, Val: 0.5616, Test: 0.5590\n",
            "Epoch: 50, Loss: 1.3556, Train: 0.5556, Val: 0.5624, Test: 0.5584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f6FQ8L1N9-f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBBCeLlAL0oL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2c3b385-ed56-4516-a3d7-5d0726021eda"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.5900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zOh6IIeI3Op",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56f61d61-8047-4a0e-eab8-0afb7817108b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8140\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}